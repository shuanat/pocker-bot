{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        \n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        \n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "    yt = tf.placeholder(tf.float32, [None, 10], name='yt')\n",
    "\n",
    "with tf.name_scope('hidden'):\n",
    "    W = tf.Variable(tf.zeros([784, 10]), name='W')\n",
    "    b = tf.Variable(tf.zeros([10]), name='b')\n",
    "    variable_summaries(W)\n",
    "    variable_summaries(b)\n",
    "\n",
    "with tf.name_scope('activations'):\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b, name='y')\n",
    "    variable_summaries(y)\n",
    "\n",
    "with tf.name_scope('test_images'):\n",
    "    image_shaped_input = tf.placeholder(tf.float32, [None, 256, 256, 1], name='image_shaped_input')\n",
    "    tf.summary.image('input', image_shaped_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(yt * tf.log(y), reduction_indices=[1]), name='cross_entropy')\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(yt,1), name='correct_prediction')\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(train_dir + '/logs/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(train_dir + '/logs/test')\n",
    "\n",
    "tf.add_to_collection('x', x)\n",
    "tf.add_to_collection('yt', yt)\n",
    "tf.add_to_collection('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(images, labels):\n",
    "    labels = labels.argmax(1)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (0,28)\n",
    "    fontScale = 1\n",
    "    fontColor = (255,255,255)\n",
    "    lineWidth = 2\n",
    "    lineType = cv2.LINE_AA\n",
    "\n",
    "    labeled_images = []\n",
    "    for idx, img in enumerate(images):\n",
    "        lbl = labels[idx]\n",
    "        img = img.reshape((28, 28)) * 255\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            str(lbl),\n",
    "            bottomLeftCornerOfText, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineWidth,\n",
    "            lineType\n",
    "        )\n",
    "\n",
    "        labeled_images.append(img.reshape((256, 256, 1)))\n",
    "    \n",
    "    return np.asarray(labeled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, yt: batch_ys})\n",
    "    train_labels = sess.run(y, feed_dict={x: batch_xs})\n",
    "    train_summary = sess.run(\n",
    "        merged, \n",
    "        feed_dict={\n",
    "            x: batch_xs,\n",
    "            yt: batch_ys,\n",
    "            image_shaped_input: draw_labels(batch_xs, train_labels)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if i % 50 == 49:\n",
    "        test_batch_xs, test_batch_ys = mnist.test.next_batch(100)\n",
    "        \n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        checkpoint_path = '%s/models/mnist.ckpt' % train_dir\n",
    "        saver.save(sess, checkpoint_path, global_step=i)\n",
    "        \n",
    "        train_writer.add_summary(train_summary, i)\n",
    "        test_labels, acc = sess.run(\n",
    "            [y, accuracy], \n",
    "            feed_dict={\n",
    "                x: test_batch_xs, \n",
    "                yt: test_batch_ys\n",
    "            }\n",
    "        )\n",
    "        test_summary = sess.run(\n",
    "            merged, \n",
    "            feed_dict={\n",
    "                x: test_batch_xs,\n",
    "                yt: test_batch_ys,\n",
    "                image_shaped_input: draw_labels(test_batch_xs, test_labels)\n",
    "            }\n",
    "        )\n",
    "        test_writer.add_summary(test_summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_dir = 'train'\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(train_dir)\n",
    "    meta_path = '%s.meta' % latest_checkpoint\n",
    "\n",
    "    saver = tf.train.import_meta_graph(meta_path)\n",
    "    saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    x = tf.get_collection('x')[0]\n",
    "    yt = tf.get_collection('yt')[0]\n",
    "    accuracy = tf.get_collection('accuracy')[0]\n",
    "\n",
    "    feed_dict={x: mnist.test.images, yt: mnist.test.labels}\n",
    "\n",
    "    print(sess.run(accuracy, feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 10, 10\n",
    "width, height = num_cols * 2, num_rows * 2\n",
    "fig = plt.figure(figsize=(width, height))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    ax = fig.add_subplot(num_rows, num_cols, i+1)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    image = mnist.test.images[i].reshape((28, 28))\n",
    "    label = mnist.test.labels[i].argmax()\n",
    "    prediction = sess.run(y, feed_dict={x: mnist.test.images[i:i+1]}).argmax()\n",
    "    ax.imshow(image, cmap='Greys', interpolation='none')\n",
    "    text = u'%i=%i'%(label, prediction) if label==prediction else u'%iâ‰ %i'%(label, prediction)\n",
    "    color = 'black' if label==prediction else 'red'\n",
    "    ax.text(\n",
    "        0, \n",
    "        0, \n",
    "        text, \n",
    "        bbox={'facecolor':'white', 'pad':5}, \n",
    "        fontdict={'size':14, 'weight': 'bold', 'color': color}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
